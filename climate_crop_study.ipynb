{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411f408b",
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "source": [
    "This Jupytr notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c8eb651",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# !/bin/sh\n",
    "\n",
    "# Install required Python packages\n",
    "!python3 -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccf96be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import builtins\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68feb5",
   "metadata": {},
   "source": [
    "Constants for file locations and column mappings used in processing GHCND climate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0fb3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants to navigate the data\n",
    "STATE_CODE = \"IA\" # state code according to ghcnd-states.\n",
    "# Sample row: \"CA001039040  50.0333 -126.8167   91.0 BC ZEBALLOS IRON MINES\"\n",
    "STATION_FILE_COLUMNS_MAPPING = {\n",
    "    \"ID\": [0, 11],\n",
    "    \"STATE\": [38, 40],\n",
    "}\n",
    "STATION_DATA_COLUMN_MAPPING = {\n",
    "    \"ID\": [0, 11],\n",
    "    \"YEAR\": [11, 15],\n",
    "    \"MONTH\": [15, 17],\n",
    "    \"ELEMENT_TYPE\": [17, 21],\n",
    "    \"ELEMENT\": [21, 26],\n",
    "}\n",
    "\n",
    "# For downloading data\n",
    "GHCND_DOWNLOAD_LOCATION = \"https://www.ncei.noaa.gov/pub/data/ghcn/daily/all/{}.dly\" # location to download data files, format with station ID\n",
    "GHCND_STATION_FILE_LOCATION = \"https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt\" # location to download ghcnd station file\n",
    "\n",
    "# For predownloaded data\n",
    "GHCND_BASE_LOCATION = \"./data/climate_data\" # base location of ghcnd data files\n",
    "STATION_FILE = f\"{GHCND_BASE_LOCATION}/raw_data/ghcnd-stations.txt\" # ghcnd station file\n",
    "GHCND_OUTPUT_FILE = f\"{GHCND_BASE_LOCATION}/processed/ghcnd-{STATE_CODE}-data.csv\" # output file for state data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd2228",
   "metadata": {},
   "source": [
    "Pull data from DLV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a8700c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_download_file(url, local_path):\n",
    "    \"\"\"Load a file from local path or download it if not present.\"\"\"\n",
    "    try:\n",
    "        f = builtins.open(local_path, 'r')\n",
    "        file_data = (line for line in f)\n",
    "        df = pd.DataFrame(file_data, columns=[\"line\"])\n",
    "        f.close()\n",
    "    except FileNotFoundError:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.text\n",
    "        file_path = Path(local_path)\n",
    "        file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with builtins.open(local_path, 'w') as f:\n",
    "            f.write(data)\n",
    "\n",
    "        f = builtins.open(local_path, 'r')\n",
    "        file_data = (line for line in f)\n",
    "        df = pd.DataFrame(file_data, columns=[\"line\"])\n",
    "        f.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "def dlv_to_filtered_df(df):\n",
    "    \"\"\"\n",
    "    Convert a DLV file to a pandas DataFrame.\n",
    "    1. Load entire DLV file into a DataFrame. With 1 single row per observation.\n",
    "    2. Split the first column into multiple columns based on fixed width.\n",
    "    3. Create dataframe with just the columns defined in STATION_DATA_COLUMN_MAPPING\n",
    "    4. Filter for ELEMENT = TMAX or TMIN by creating two separate dataframes and merging them on MONTH and YEAR.\n",
    "    5. Calculate TAVG as the average of TMAX and TMIN.\n",
    "    6. Return the final DataFrame.\n",
    "    \"\"\"\n",
    "    for col_name, (start, end) in STATION_DATA_COLUMN_MAPPING.items():\n",
    "        df[col_name] = df[\"line\"].str[start:end].str.strip()\n",
    "    df = df[list(STATION_DATA_COLUMN_MAPPING.keys())]\n",
    "\n",
    "    tmax_df = df[df[\"ELEMENT_TYPE\"] == \"TMAX\"][[\"YEAR\", \"MONTH\", \"ID\", \"ELEMENT\"]].rename(columns={\"ELEMENT\": \"TMAX\"})\n",
    "    tmax_df = tmax_df[tmax_df[\"TMAX\"] != '-9999']\n",
    "\n",
    "    tmin_df = df[df[\"ELEMENT_TYPE\"] == \"TMIN\"][[\"YEAR\", \"MONTH\", \"ID\", \"ELEMENT\"]].rename(columns={\"ELEMENT\": \"TMIN\"})\n",
    "    tmin_df = tmin_df[tmin_df[\"TMIN\"] != '-9999']\n",
    "\n",
    "    df = pd.merge(tmax_df, tmin_df, on=[\"YEAR\", \"MONTH\", \"ID\"], how=\"outer\")\n",
    "    df[\"TAVG\"] = (df[\"TMAX\"].astype(float) + df[\"TMIN\"].astype(float)) / 2\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_state_stations(state_code=STATE_CODE):\n",
    "    \"\"\"Get list of station IDs for the specified state.\"\"\"\n",
    "    df = load_or_download_file(\n",
    "        GHCND_STATION_FILE_LOCATION,\n",
    "        STATION_FILE\n",
    "    )\n",
    "    for col_name, (start, end) in STATION_FILE_COLUMNS_MAPPING.items():\n",
    "        df[col_name] = df[\"line\"].str[start:end].str.strip()\n",
    "    stations_df = df[list(STATION_FILE_COLUMNS_MAPPING.keys())]\n",
    "    state_stations_df = stations_df[stations_df[\"STATE\"] == state_code]\n",
    "    stations_list = state_stations_df[\"ID\"].tolist()\n",
    "    return stations_list\n",
    "\n",
    "def get_state_data(state_code=STATE_CODE):\n",
    "    \"\"\"Get climate data for the specified state.\"\"\"\n",
    "    stations_list = get_state_stations(state_code)\n",
    "    all_data_df = pd.DataFrame()\n",
    "    for station_id in stations_list:\n",
    "        station_data_df = load_or_download_file(\n",
    "            GHCND_DOWNLOAD_LOCATION.format(station_id),\n",
    "            f\"{GHCND_BASE_LOCATION}/raw_data/ghcnd_gsn/{station_id}.dlv\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            station_data_df = dlv_to_filtered_df(station_data_df)\n",
    "            all_data_df = pd.concat([all_data_df, station_data_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"DLV file not found for station {station_id}, skipping.\")\n",
    "    return all_data_df\n",
    "\n",
    "def get_mean_temperature_per_year(state_code=STATE_CODE):\n",
    "    \"\"\"Get mean temperature per year for the specified state.\"\"\"\n",
    "    try:\n",
    "        file_path = Path(GHCND_OUTPUT_FILE)\n",
    "        file_path.parent.mkdir(parents=True, exist_ok=True)        \n",
    "        \n",
    "        mean_temp_per_year_df = pd.read_csv(GHCND_OUTPUT_FILE)\n",
    "    except FileNotFoundError:\n",
    "        state_data_df = get_state_data(state_code)\n",
    "        mean_temp_per_year_df = state_data_df.groupby(\"YEAR\")[\"TAVG\"].mean().reset_index()\n",
    "        mean_temp_per_year_df.rename(columns={\"TAVG\": \"MEAN_TAVG\"}, inplace=True)\n",
    "        mean_temp_per_year_df.to_csv(GHCND_OUTPUT_FILE, index=False)\n",
    "    return mean_temp_per_year_df\n",
    "\n",
    "mean_temperature_per_year_df = get_mean_temperature_per_year()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa90533",
   "metadata": {},
   "source": [
    "Pull data from crop.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e286919",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_DATA_BASE_LOCATION = \"./data/crop_data\" # base location of crop data files\n",
    "STATE = \"IOWA\" # state name for crop data\n",
    "\n",
    "# For predownloaded data\n",
    "CROP_DATA_FILE = f\"{CROP_DATA_BASE_LOCATION}/raw_data/corn.csv\" # crop data\n",
    "CROP_OUTPUT_FILE = f\"{CROP_DATA_BASE_LOCATION}/processed/crop.csv\" # output file for crop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cbf9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crop_data():\n",
    "    \"\"\"Load crop data from CSV file.\"\"\"\n",
    "    try:\n",
    "        crop_df = pd.read_csv(CROP_OUTPUT_FILE)\n",
    "    except FileNotFoundError:\n",
    "        crop_df = pd.read_csv(CROP_DATA_FILE, header=0)\n",
    "        crop_df = crop_df[\n",
    "            (crop_df[\"Period\"] == \"YEAR\") &\\\n",
    "            (crop_df[\"State\"] == STATE) &\\\n",
    "            (crop_df[\"Commodity\"] == \"CORN\")\n",
    "        ]\n",
    "        crop_df = crop_df[[\"Year\", \"Value\"]]\n",
    "\n",
    "        file_path = Path(CROP_OUTPUT_FILE)\n",
    "        file_path.parent.mkdir(parents=True, exist_ok=True)        \n",
    "        crop_data_df.to_csv(CROP_OUTPUT_FILE, index=False)\n",
    "    return crop_df\n",
    "\n",
    "crop_data_df = load_crop_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386688e9",
   "metadata": {},
   "source": [
    "Merge the data into a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c608b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4755cbc6",
   "metadata": {},
   "source": [
    "Draw graphs based on the dataframe to compare averge temperatures to crop yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
